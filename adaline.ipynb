{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNqtIdOnQA45TRAmGBIs8UX"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LSgTnrfoN1QT","executionInfo":{"status":"ok","timestamp":1681651132304,"user_tz":-330,"elapsed":638,"user":{"displayName":"Anubhav Kharwar","userId":"17249186974872255626"}},"outputId":"0aeee80a-eb19-4cb4-8788-639f36e1d525"},"outputs":[{"output_type":"stream","name":"stdout","text":["[[-1 -1]\n"," [-1  1]\n"," [ 1 -1]\n"," [ 1  1]] [-1 -1 -1  1]\n","epoch: 1\n","epoch: 2\n","epoch: 3\n","epoch: 4\n","epoch: 5\n","epoch: 6\n","epoch: 7\n","epoch: 8\n","epoch: 9\n","epoch: 10\n","epoch: 11\n","epoch: 12\n","epoch: 13\n","epoch: 14\n","epoch: 15\n","epoch: 16\n","epoch: 17\n","epoch: 18\n","epoch: 19\n","epoch: 20\n","epoch: 21\n","epoch: 22\n","epoch: 23\n","epoch: 24\n","epoch: 25\n","epoch: 26\n","epoch: 27\n","epoch: 28\n","epoch: 29\n","epoch: 30\n","epoch: 31\n","epoch: 32\n","epoch: 33\n","epoch: 34\n","epoch: 35\n","epoch: 36\n","epoch: 37\n","epoch: 38\n","epoch: 39\n","epoch: 40\n","epoch: 41\n","epoch: 42\n","epoch: 43\n","epoch: 44\n","epoch: 45\n","epoch: 46\n","epoch: 47\n","epoch: 48\n","epoch: 49\n","epoch: 50\n","epoch: 51\n","epoch: 52\n","epoch: 53\n","epoch: 54\n","epoch: 55\n","epoch: 56\n","epoch: 57\n","epoch: 58\n","epoch: 59\n","epoch: 60\n","epoch: 61\n","epoch: 62\n","epoch: 63\n","epoch: 64\n","epoch: 65\n","epoch: 66\n","epoch: 67\n","epoch: 68\n","epoch: 69\n","epoch: 70\n","epoch: 71\n","epoch: 72\n","epoch: 73\n","epoch: 74\n","epoch: 75\n","epoch: 76\n","epoch: 77\n","epoch: 78\n","epoch: 79\n","epoch: 80\n","epoch: 81\n","epoch: 82\n","epoch: 83\n","epoch: 84\n","epoch: 85\n","epoch: 86\n","epoch: 87\n","epoch: 88\n","epoch: 89\n","epoch: 90\n","epoch: 91\n","epoch: 92\n","epoch: 93\n","epoch: 94\n","epoch: 95\n","epoch: 96\n","epoch: 97\n","epoch: 98\n","epoch: 99\n","epoch: 100\n","error = -0.09999999999999998\n","error = -1.05\n","error = -1.5750000000000002\n","error = 1.1625\n","sum of squared error =  1.2361328125000002 \n","\n","\n"]}],"source":["# import the module numpy\n","import numpy as np\n","#implementing AND\n","features = np.array([[-1,-1],[-1,1],[1,-1],[1,1]])\n","#tagged values\n","labels = np.array([-1,-1,-1,1])\n","print(features, labels)\n","# initialise weights, bias , learning rate, epoch\n","weight = [0.5,0.5]\n","bias= 0.1\n","learning_rate=0.5\n","epoch = 100\n","for i in range(epoch):\n"," print(\"epoch:\",i+1)\n"," sum_squared_error = 0.0\n","for j in range(features.shape[0]):\n"," actual = labels[j]\n"," x1 = features[j][0]\n"," x2 = features[j][1]\n"," unit = (x1 * weight[0]) + (x2 * weight[1]) + bias\n"," error = actual - unit\n"," print(\"error =\",error)\n"," sum_squared_error += error * error\n"," weight[0] += learning_rate * error * x1\n"," weight[1] += learning_rate * error * x2\n"," bias += learning_rate * error\n","print(\"sum of squared error = \", sum_squared_error/4,\"\\n\\n\")"]}]}